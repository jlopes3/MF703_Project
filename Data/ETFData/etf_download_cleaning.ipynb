{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is used to download, clean, and merge the ETF data from Yahoo Finance. Missing data is filled using forward filling. The cleaned data is written to individual csv files in the Cleaned folder and a merged file is written to merged_cleaned_etf_data.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from functools import reduce\n",
    "\n",
    "tickers = ['SPY', 'XLB', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLU', 'XLV', 'XLY', '^GSPC', 'BND', 'GLD', 'QQQ', 'VTI']\n",
    "dfs = []\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=\"1992-01-01\", end=\"2020-12-31\")['Adj Close'].rename(columns={ticker: \"Adj Close\"}).reset_index()\n",
    "    data['Date'] = data['Date'].dt.date\n",
    "    data = data.ffill().dropna()\n",
    "    data.to_csv(\"Cleaned/\"+ticker+\".csv\", index=True, header=True)\n",
    "    data.rename(columns={'Adj Close': ticker + ' Adj Close'})\n",
    "    dfs += [(data, ticker)]\n",
    "\n",
    "final_dfs = []\n",
    "for df, ticker in dfs:\n",
    "    final_dfs += [df.rename(columns={'Adj Close': ticker + ' Adj Close'})]\n",
    "\n",
    "merged_df = reduce(lambda x, y: pd.merge(x, y, how='inner', on=\"Date\"), final_dfs)\n",
    "merged_df.to_csv(\"merged_cleaned_etf_data.csv\", index=True, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
